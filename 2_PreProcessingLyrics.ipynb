{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f9d582c-0c33-4b31-a946-7f61c9c2a279",
   "metadata": {},
   "source": [
    "# Pre-Processing\n",
    "\n",
    "Description: This code takes in our Translated_Lyrics.csv and produces our Core tables we will use to analyze our data. Due to the vast amount of songs we took a sample of 500 songs per Genre\n",
    "\n",
    "### Output\n",
    "\n",
    "1. VOCAB.csv\n",
    "2. TOKEN.csv\n",
    "3. LIB.csv\n",
    "3. TFIDF.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c34b415-0bcc-4376-b9c0-603edd971809",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.linalg import norm\n",
    "from scipy.linalg import eigh as eig\n",
    "import plotly_express as px\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation as LDA\n",
    "import scipy.cluster.hierarchy as sch\n",
    "from scipy.spatial.distance import pdist\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import word2vec\n",
    "from sklearn.manifold import TSNE\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyser = SentimentIntensityAnalyzer()\n",
    "from matplotlib.pyplot import figure\n",
    "figure(figsize=(8, 6), dpi=80)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb59dd31-efd8-4b83-883b-7c8a81465eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "All_Lyrics = \"Translated_Lyrics.csv\"\n",
    "Artists_File = \"artists-data.csv\"\n",
    "All_Lyrics_df = pd.read_csv (All_Lyrics)\n",
    "artists_df = pd.read_csv(Artists_File)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af9b50ad-1549-4581-9a03-0b6a16670163",
   "metadata": {},
   "source": [
    "### Build out LIB and DOC Tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19e258e7-79b9-4858-8143-26d1bf583ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCO = ['Genre', 'Artist',  'SName','Language', 'sent_num', 'token_num']\n",
    "All_Lyrics_df = All_Lyrics_df.drop(columns=['Unnamed: 0'])\n",
    "All_Lyrics_df = All_Lyrics_df.rename(columns={'ALink': 'Link'})\n",
    "All_Lyrics_df = All_Lyrics_df.rename(columns={'Idiom': 'Language'})\n",
    "result = pd.merge(All_Lyrics_df, artists_df, how=\"left\", on=[\"Link\"])\n",
    "Lang_agg = result.groupby(\"Language\").size()\n",
    "DOC = result[['Genre', 'Artist','Language','SName', 'Translated_Lyrics']]\n",
    "\n",
    "DOC= DOC.drop_duplicates()\n",
    "\n",
    "\n",
    "LIB = DOC[['Genre', 'Artist','SName']]\n",
    "\n",
    "LIB.Genre = pd.Categorical(LIB.Genre)\n",
    "LIB['Genre_Index'] = LIB.Genre.cat.codes\n",
    "\n",
    "\n",
    "LIB.Artist = pd.Categorical(LIB.Artist)\n",
    "LIB['Artist_Index'] = LIB.Artist.cat.codes\n",
    "\n",
    "\n",
    "LIB.SName = pd.Categorical(LIB.SName)\n",
    "LIB['SName_Index'] = LIB.SName.cat.codes\n",
    "\n",
    "\n",
    "DOC = DOC.groupby(\"Genre\").sample(n=500, random_state=113)\n",
    "DOC = DOC.set_index(['Genre', 'Artist',  'SName','Language'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf4d80d-7484-4414-a0a3-5fd23dbacb4c",
   "metadata": {},
   "source": [
    "### All Languages Present Before Reduction in Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43c7a704-a121-4970-9134-cc15e6d7c23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Language\n",
       "ENGLISH       129396\n",
       "PORTUGUESE     94892\n",
       "SPANISH         5211\n",
       "ITALIAN          640\n",
       "FRENCH           482\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Lang_agg.nlargest()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e575eb9f-38a7-465a-bad6-54f608f476f1",
   "metadata": {},
   "source": [
    "### Even Distribution of Each Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e9655e8-f014-4cc4-a649-3d0d71274666",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Genre\n",
       "Funk Carioca    500\n",
       "Hip Hop         500\n",
       "Pop             500\n",
       "Rock            500\n",
       "Samba           500\n",
       "Sertanejo       500\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DOC.groupby(\"Genre\").size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f54b135-f366-4604-8b9c-fb3371a8866e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Genre</th>\n",
       "      <th>Artist</th>\n",
       "      <th>SName</th>\n",
       "      <th>Genre_Index</th>\n",
       "      <th>Artist_Index</th>\n",
       "      <th>SName_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rock</td>\n",
       "      <td>311</td>\n",
       "      <td>Summer Of Love - Traducao</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>103488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rock</td>\n",
       "      <td>4SERES</td>\n",
       "      <td>Morada</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>69044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rock</td>\n",
       "      <td>A Corte Animal</td>\n",
       "      <td>À Deriva</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>126890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rock</td>\n",
       "      <td>A Corte Animal</td>\n",
       "      <td>À Flor da Pele Moderna</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>126896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Rock</td>\n",
       "      <td>A Corte Animal</td>\n",
       "      <td>De Brasília, Com Amor</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>26208</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Genre          Artist                      SName  Genre_Index  Artist_Index  \\\n",
       "0  Rock             311  Summer Of Love - Traducao            3            13   \n",
       "2  Rock          4SERES                     Morada            3            18   \n",
       "3  Rock  A Corte Animal                   À Deriva            3            20   \n",
       "4  Rock  A Corte Animal     À Flor da Pele Moderna            3            20   \n",
       "5  Rock  A Corte Animal      De Brasília, Com Amor            3            20   \n",
       "\n",
       "   SName_Index  \n",
       "0       103488  \n",
       "2        69044  \n",
       "3       126890  \n",
       "4       126896  \n",
       "5        26208  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LIB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2862d2-f953-4e98-9f52-e44c6a4add7f",
   "metadata": {},
   "source": [
    "### Build out TOKEN Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5c3eefb7-4cf1-4081-a56f-2d44b64a4a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(doc_df, OHCO=OHCO, remove_pos_tuple=False, ws=False):\n",
    "    \n",
    "\n",
    "    df = doc_df.Translated_Lyrics\\\n",
    "        .apply(lambda x: pd.Series(nltk.sent_tokenize(x)))\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'sent_str'})\n",
    "    \n",
    "    def word_tokenize(x):\n",
    "        if ws:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.WhitespaceTokenizer().tokenize(x)))\n",
    "        else:\n",
    "            s = pd.Series(nltk.pos_tag(nltk.word_tokenize(x))) # Discards stuff in between\n",
    "        return s\n",
    "            \n",
    "    df = df.sent_str\\\n",
    "        .apply(word_tokenize)\\\n",
    "        .stack()\\\n",
    "        .to_frame()\\\n",
    "        .rename(columns={0:'pos_tuple'})\n",
    "    \n",
    "    # Grab info from tuple\n",
    "    df['pos'] = df.pos_tuple.apply(lambda x: x[1])\n",
    "    df['token_str'] = df.pos_tuple.apply(lambda x: x[0])\n",
    "    if remove_pos_tuple:\n",
    "        df = df.drop('pos_tuple', 1)\n",
    "    \n",
    "    # Add index\n",
    "    df.index.names = OHCO\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19107b55-7b68-4d20-a164-d4433326cdeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "TOKEN = tokenize(DOC, ws=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7facc2a0-4361-4850-a52f-cf3ecd4eef2e",
   "metadata": {},
   "source": [
    "### Build out VOCAB Table, Give POS, Zips Features, and Rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcce03f6-4bc5-48df-9db8-2bb952e8acb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN = TOKEN.dropna()\n",
    "TOKEN['term_str'] = TOKEN['token_str'].str.lower().str.replace('[\\W_]', '')\n",
    "TOKEN = TOKEN[TOKEN['term_str'] != \"\"]\n",
    "VOCAB = TOKEN.term_str.value_counts().to_frame()\\\n",
    "    .rename(columns={'index':'term_str', 'term_str':'n'})\\\n",
    "    .sort_index().reset_index().rename(columns={'index':'term_str'})\n",
    "VOCAB.index.name = 'term_id'\n",
    "VOCAB['num'] = VOCAB.term_str.str.match(\"\\d+\").astype('int')\n",
    "\n",
    "\n",
    "TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)\n",
    "VOCAB['pos_max'] = TOKEN.groupby(['term_id', 'pos']).count().iloc[:,0].unstack().idxmax(1)\n",
    "VOCAB = VOCAB.sort_values('n', ascending=False).reset_index()\n",
    "VOCAB.index.name = 'term_rank'\n",
    "VOCAB = VOCAB.reset_index()\n",
    "VOCAB = VOCAB.set_index('term_id')\n",
    "VOCAB['term_rank'] = VOCAB['term_rank'] + 1\n",
    "new_rank = VOCAB.n.value_counts()\\\n",
    "    .sort_index(ascending=False).reset_index().reset_index()\\\n",
    "    .rename(columns={'level_0':'term_rank2', 'index':'n', 'n':'nn'})\\\n",
    "    .set_index('n')\n",
    "VOCAB['p'] = VOCAB.n / TOKEN.shape[0]\n",
    "VOCAB['term_rank2'] = VOCAB.n.map(new_rank.term_rank2) + 1\n",
    "VOCAB['zipf_k'] = VOCAB.n * VOCAB.term_rank\n",
    "VOCAB['zipf_k2'] = VOCAB.n * VOCAB.term_rank2\n",
    "VOCAB['zipf_k3'] = VOCAB.p * VOCAB.term_rank2\n",
    "VOCAB['p'] = VOCAB.n / VOCAB.n.sum()\n",
    "VOCAB = VOCAB.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "49ec0208-5b38-40a4-8277-09225d5cf84c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>pos_tuple</th>\n",
       "      <th>pos</th>\n",
       "      <th>token_str</th>\n",
       "      <th>term_str</th>\n",
       "      <th>term_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Genre</th>\n",
       "      <th>Artist</th>\n",
       "      <th>SName</th>\n",
       "      <th>Language</th>\n",
       "      <th>sent_num</th>\n",
       "      <th>token_num</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Funk Carioca</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Marcos e Fernando</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">Papo de Jacaré</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">PORTUGUESE</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>(Im, NNP)</td>\n",
       "      <td>NNP</td>\n",
       "      <td>Im</td>\n",
       "      <td>im</td>\n",
       "      <td>10645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(riding, VBG)</td>\n",
       "      <td>VBG</td>\n",
       "      <td>riding</td>\n",
       "      <td>riding</td>\n",
       "      <td>18060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(this, DT)</td>\n",
       "      <td>DT</td>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "      <td>21659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(girls, NNS)</td>\n",
       "      <td>NNS</td>\n",
       "      <td>girls</td>\n",
       "      <td>girls</td>\n",
       "      <td>8975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(wave, VBP)</td>\n",
       "      <td>VBP</td>\n",
       "      <td>wave</td>\n",
       "      <td>wave</td>\n",
       "      <td>23504</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                 pos_tuple  \\\n",
       "Genre        Artist            SName          Language   sent_num token_num                  \n",
       "Funk Carioca Marcos e Fernando Papo de Jacaré PORTUGUESE 0        0              (Im, NNP)   \n",
       "                                                                  1          (riding, VBG)   \n",
       "                                                                  2             (this, DT)   \n",
       "                                                                  3           (girls, NNS)   \n",
       "                                                                  4            (wave, VBP)   \n",
       "\n",
       "                                                                             pos  \\\n",
       "Genre        Artist            SName          Language   sent_num token_num        \n",
       "Funk Carioca Marcos e Fernando Papo de Jacaré PORTUGUESE 0        0          NNP   \n",
       "                                                                  1          VBG   \n",
       "                                                                  2           DT   \n",
       "                                                                  3          NNS   \n",
       "                                                                  4          VBP   \n",
       "\n",
       "                                                                            token_str  \\\n",
       "Genre        Artist            SName          Language   sent_num token_num             \n",
       "Funk Carioca Marcos e Fernando Papo de Jacaré PORTUGUESE 0        0                Im   \n",
       "                                                                  1            riding   \n",
       "                                                                  2              this   \n",
       "                                                                  3             girls   \n",
       "                                                                  4              wave   \n",
       "\n",
       "                                                                            term_str  \\\n",
       "Genre        Artist            SName          Language   sent_num token_num            \n",
       "Funk Carioca Marcos e Fernando Papo de Jacaré PORTUGUESE 0        0               im   \n",
       "                                                                  1           riding   \n",
       "                                                                  2             this   \n",
       "                                                                  3            girls   \n",
       "                                                                  4             wave   \n",
       "\n",
       "                                                                             term_id  \n",
       "Genre        Artist            SName          Language   sent_num token_num           \n",
       "Funk Carioca Marcos e Fernando Papo de Jacaré PORTUGUESE 0        0            10645  \n",
       "                                                                  1            18060  \n",
       "                                                                  2            21659  \n",
       "                                                                  3             8975  \n",
       "                                                                  4            23504  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TOKEN.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17474c0d-1c6d-41fe-ab52-976c22d29a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>p</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13142</th>\n",
       "      <td>21375</td>\n",
       "      <td>manguin</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>21375</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10245</th>\n",
       "      <td>7756</td>\n",
       "      <td>hoodie</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>523</td>\n",
       "      <td>31024</td>\n",
       "      <td>2092</td>\n",
       "      <td>0.002877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2723</th>\n",
       "      <td>2659</td>\n",
       "      <td>bouncing</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>VBG</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>509</td>\n",
       "      <td>47862</td>\n",
       "      <td>9162</td>\n",
       "      <td>0.012600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7852</th>\n",
       "      <td>17669</td>\n",
       "      <td>felly</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>17669</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15718</th>\n",
       "      <td>4902</td>\n",
       "      <td>password</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>520</td>\n",
       "      <td>34314</td>\n",
       "      <td>3640</td>\n",
       "      <td>0.005006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9888</th>\n",
       "      <td>22501</td>\n",
       "      <td>heavyweight</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>22501</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18226</th>\n",
       "      <td>635</td>\n",
       "      <td>rolling</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>VBG</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>412</td>\n",
       "      <td>73660</td>\n",
       "      <td>47792</td>\n",
       "      <td>0.065723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14187</th>\n",
       "      <td>20899</td>\n",
       "      <td>mufuckas</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>20899</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6802</th>\n",
       "      <td>18138</td>\n",
       "      <td>e55</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>18138</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16538</th>\n",
       "      <td>21810</td>\n",
       "      <td>portela</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>21810</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank     term_str    n  num pos_max         p  term_rank2  \\\n",
       "term_id                                                                   \n",
       "13142        21375      manguin    1    0     NNP  0.000001         526   \n",
       "10245         7756       hoodie    4    0      NN  0.000006         523   \n",
       "2723          2659     bouncing   18    0     VBG  0.000025         509   \n",
       "7852         17669        felly    1    0      RB  0.000001         526   \n",
       "15718         4902     password    7    0      NN  0.000010         520   \n",
       "9888         22501  heavyweight    1    0      JJ  0.000001         526   \n",
       "18226          635      rolling  116    0     VBG  0.000160         412   \n",
       "14187        20899     mufuckas    1    0      NN  0.000001         526   \n",
       "6802         18138          e55    1    0      NN  0.000001         526   \n",
       "16538        21810      portela    1    0      NN  0.000001         526   \n",
       "\n",
       "         zipf_k  zipf_k2   zipf_k3  \n",
       "term_id                             \n",
       "13142     21375      526  0.000723  \n",
       "10245     31024     2092  0.002877  \n",
       "2723      47862     9162  0.012600  \n",
       "7852      17669      526  0.000723  \n",
       "15718     34314     3640  0.005006  \n",
       "9888      22501      526  0.000723  \n",
       "18226     73660    47792  0.065723  \n",
       "14187     20899      526  0.000723  \n",
       "6802      18138      526  0.000723  \n",
       "16538     21810      526  0.000723  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7b3d75ee-41e9-4c74-9e4b-31338c97375a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = pd.DataFrame(nltk.corpus.stopwords.words('english'), columns=['term_str'])\n",
    "sw = sw.reset_index().set_index('term_str')\n",
    "sw.columns = ['dummy']\n",
    "sw.dummy = 1\n",
    "VOCAB['stop'] = VOCAB.term_str.map(sw.dummy)\n",
    "VOCAB['stop'] = VOCAB['stop'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "27249d03-a979-41cd-9efb-b9756bd7f51b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>p</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "      <th>stop</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14327</th>\n",
       "      <td>9</td>\n",
       "      <td>my</td>\n",
       "      <td>9993</td>\n",
       "      <td>0</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>0.013742</td>\n",
       "      <td>9</td>\n",
       "      <td>89937</td>\n",
       "      <td>89937</td>\n",
       "      <td>0.123681</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15373</th>\n",
       "      <td>1898</td>\n",
       "      <td>ourselves</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>PRP</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>499</td>\n",
       "      <td>53144</td>\n",
       "      <td>13972</td>\n",
       "      <td>0.019214</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15372</th>\n",
       "      <td>1043</td>\n",
       "      <td>ours</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>467</td>\n",
       "      <td>62580</td>\n",
       "      <td>28020</td>\n",
       "      <td>0.038533</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>7458</td>\n",
       "      <td>couldn</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>523</td>\n",
       "      <td>29832</td>\n",
       "      <td>2092</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9973</th>\n",
       "      <td>75</td>\n",
       "      <td>her</td>\n",
       "      <td>1455</td>\n",
       "      <td>0</td>\n",
       "      <td>PRP$</td>\n",
       "      <td>0.002001</td>\n",
       "      <td>75</td>\n",
       "      <td>109125</td>\n",
       "      <td>109125</td>\n",
       "      <td>0.150068</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21599</th>\n",
       "      <td>10770</td>\n",
       "      <td>theirs</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>525</td>\n",
       "      <td>21540</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21572</th>\n",
       "      <td>177</td>\n",
       "      <td>than</td>\n",
       "      <td>542</td>\n",
       "      <td>0</td>\n",
       "      <td>IN</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>168</td>\n",
       "      <td>95934</td>\n",
       "      <td>91056</td>\n",
       "      <td>0.125220</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21604</th>\n",
       "      <td>125</td>\n",
       "      <td>then</td>\n",
       "      <td>834</td>\n",
       "      <td>0</td>\n",
       "      <td>RB</td>\n",
       "      <td>0.001147</td>\n",
       "      <td>123</td>\n",
       "      <td>104250</td>\n",
       "      <td>102582</td>\n",
       "      <td>0.141070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14982</th>\n",
       "      <td>527</td>\n",
       "      <td>o</td>\n",
       "      <td>156</td>\n",
       "      <td>0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>374</td>\n",
       "      <td>82212</td>\n",
       "      <td>58344</td>\n",
       "      <td>0.080234</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>937</th>\n",
       "      <td>117</td>\n",
       "      <td>an</td>\n",
       "      <td>917</td>\n",
       "      <td>0</td>\n",
       "      <td>DT</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>115</td>\n",
       "      <td>107289</td>\n",
       "      <td>105455</td>\n",
       "      <td>0.145021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank   term_str     n  num pos_max         p  term_rank2  \\\n",
       "term_id                                                                  \n",
       "14327            9         my  9993    0    PRP$  0.013742           9   \n",
       "15373         1898  ourselves    28    0     PRP  0.000039         499   \n",
       "15372         1043       ours    60    0     NNS  0.000083         467   \n",
       "4991          7458     couldn     4    0     NNP  0.000006         523   \n",
       "9973            75        her  1455    0    PRP$  0.002001          75   \n",
       "21599        10770     theirs     2    0     NNS  0.000003         525   \n",
       "21572          177       than   542    0      IN  0.000745         168   \n",
       "21604          125       then   834    0      RB  0.001147         123   \n",
       "14982          527          o   156    0     NNP  0.000215         374   \n",
       "937            117         an   917    0      DT  0.001261         115   \n",
       "\n",
       "         zipf_k  zipf_k2   zipf_k3  stop  \n",
       "term_id                                   \n",
       "14327     89937    89937  0.123681     1  \n",
       "15373     53144    13972  0.019214     1  \n",
       "15372     62580    28020  0.038533     1  \n",
       "4991      29832     2092  0.002877     1  \n",
       "9973     109125   109125  0.150068     1  \n",
       "21599     21540     1050  0.001444     1  \n",
       "21572     95934    91056  0.125220     1  \n",
       "21604    104250   102582  0.141070     1  \n",
       "14982     82212    58344  0.080234     1  \n",
       "937      107289   105455  0.145021     1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB[VOCAB.stop == 1].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27736cf-2c4e-463b-bfdf-5ec785ecd84b",
   "metadata": {},
   "source": [
    "### Build Out Stemmers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "afc57e12-8464-4b25-83e3-132bbb7dd3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer1 = PorterStemmer()\n",
    "VOCAB['stem_porter'] = VOCAB.term_str.apply(stemmer1.stem)\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer2 = SnowballStemmer(\"english\")\n",
    "VOCAB['stem_snowball'] = VOCAB.term_str.apply(stemmer2.stem)\n",
    "\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "stemmer3 = LancasterStemmer()\n",
    "VOCAB['stem_lancaster'] = VOCAB.term_str.apply(stemmer3.stem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "39c3fe17-c918-4adf-9354-9afeb9a2a11e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_rank</th>\n",
       "      <th>term_str</th>\n",
       "      <th>n</th>\n",
       "      <th>num</th>\n",
       "      <th>pos_max</th>\n",
       "      <th>p</th>\n",
       "      <th>term_rank2</th>\n",
       "      <th>zipf_k</th>\n",
       "      <th>zipf_k2</th>\n",
       "      <th>zipf_k3</th>\n",
       "      <th>stop</th>\n",
       "      <th>stem_porter</th>\n",
       "      <th>stem_snowball</th>\n",
       "      <th>stem_lancaster</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>term_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11645</th>\n",
       "      <td>13185</td>\n",
       "      <td>kaka</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>525</td>\n",
       "      <td>26370</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0</td>\n",
       "      <td>kaka</td>\n",
       "      <td>kaka</td>\n",
       "      <td>kak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406</th>\n",
       "      <td>10675</td>\n",
       "      <td>runny</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>525</td>\n",
       "      <td>21350</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0</td>\n",
       "      <td>runni</td>\n",
       "      <td>runni</td>\n",
       "      <td>runny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3754</th>\n",
       "      <td>8144</td>\n",
       "      <td>cest</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NNP</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>524</td>\n",
       "      <td>24432</td>\n",
       "      <td>1572</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0</td>\n",
       "      <td>cest</td>\n",
       "      <td>cest</td>\n",
       "      <td>cest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14945</th>\n",
       "      <td>22078</td>\n",
       "      <td>nunmullodo</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>JJ</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>22078</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0</td>\n",
       "      <td>nunmullodo</td>\n",
       "      <td>nunmullodo</td>\n",
       "      <td>nunmullodo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5902</th>\n",
       "      <td>4692</td>\n",
       "      <td>deserts</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>519</td>\n",
       "      <td>37536</td>\n",
       "      <td>4152</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0</td>\n",
       "      <td>desert</td>\n",
       "      <td>desert</td>\n",
       "      <td>desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15075</th>\n",
       "      <td>5447</td>\n",
       "      <td>officer</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>521</td>\n",
       "      <td>32682</td>\n",
       "      <td>3126</td>\n",
       "      <td>0.004299</td>\n",
       "      <td>0</td>\n",
       "      <td>offic</td>\n",
       "      <td>offic</td>\n",
       "      <td>off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15857</th>\n",
       "      <td>21547</td>\n",
       "      <td>peeyimp</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>21547</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0</td>\n",
       "      <td>peeyimp</td>\n",
       "      <td>peeyimp</td>\n",
       "      <td>peeyimp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12490</th>\n",
       "      <td>10208</td>\n",
       "      <td>lightens</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>525</td>\n",
       "      <td>20416</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0</td>\n",
       "      <td>lighten</td>\n",
       "      <td>lighten</td>\n",
       "      <td>light</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19653</th>\n",
       "      <td>12732</td>\n",
       "      <td>skeet</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NN</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>525</td>\n",
       "      <td>25464</td>\n",
       "      <td>1050</td>\n",
       "      <td>0.001444</td>\n",
       "      <td>0</td>\n",
       "      <td>skeet</td>\n",
       "      <td>skeet</td>\n",
       "      <td>skeet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23814</th>\n",
       "      <td>16063</td>\n",
       "      <td>windmills</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>NNS</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>526</td>\n",
       "      <td>16063</td>\n",
       "      <td>526</td>\n",
       "      <td>0.000723</td>\n",
       "      <td>0</td>\n",
       "      <td>windmil</td>\n",
       "      <td>windmil</td>\n",
       "      <td>windmil</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         term_rank    term_str  n  num pos_max         p  term_rank2  zipf_k  \\\n",
       "term_id                                                                        \n",
       "11645        13185        kaka  2    0     NNP  0.000003         525   26370   \n",
       "18406        10675       runny  2    0      JJ  0.000003         525   21350   \n",
       "3754          8144        cest  3    0     NNP  0.000004         524   24432   \n",
       "14945        22078  nunmullodo  1    0      JJ  0.000001         526   22078   \n",
       "5902          4692     deserts  8    0     NNS  0.000011         519   37536   \n",
       "15075         5447     officer  6    0      NN  0.000008         521   32682   \n",
       "15857        21547     peeyimp  1    0      NN  0.000001         526   21547   \n",
       "12490        10208    lightens  2    0     NNS  0.000003         525   20416   \n",
       "19653        12732       skeet  2    0      NN  0.000003         525   25464   \n",
       "23814        16063   windmills  1    0     NNS  0.000001         526   16063   \n",
       "\n",
       "         zipf_k2   zipf_k3  stop stem_porter stem_snowball stem_lancaster  \n",
       "term_id                                                                    \n",
       "11645       1050  0.001444     0        kaka          kaka            kak  \n",
       "18406       1050  0.001444     0       runni         runni          runny  \n",
       "3754        1572  0.002162     0        cest          cest           cest  \n",
       "14945        526  0.000723     0  nunmullodo    nunmullodo     nunmullodo  \n",
       "5902        4152  0.005710     0      desert        desert         desert  \n",
       "15075       3126  0.004299     0       offic         offic            off  \n",
       "15857        526  0.000723     0     peeyimp       peeyimp        peeyimp  \n",
       "12490       1050  0.001444     0     lighten       lighten          light  \n",
       "19653       1050  0.001444     0       skeet         skeet          skeet  \n",
       "23814        526  0.000723     0     windmil       windmil        windmil  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "VOCAB.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e636c97-57d5-400a-bfe0-a83bf1b241a2",
   "metadata": {},
   "source": [
    "### TFIDF Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2e470a72-4b8f-4207-89bf-3a7a567766a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def TFIDF_FUNCTION(TOKEN, bag, count_type, tf_method, idf_method):\n",
    "    TOKEN = TOKEN[~TOKEN.term_str.isna()]\n",
    "    #TOKEN['term_id'] = TOKEN.term_str.map(VOCAB.reset_index().set_index('term_str').term_id)\n",
    "    #TOKEN.reset_index().set_index('term_str').term_id\n",
    "    BOW = TOKEN.groupby(bag+['term_id']).term_id.count()\\\n",
    "    .to_frame().rename(columns={'term_id':'n'})\n",
    "    BOW['c'] = BOW.n.astype('bool').astype('int')\n",
    "    DTCM = BOW[count_type].unstack().fillna(0).astype('int')\n",
    "    \n",
    "    if tf_method == 'sum':\n",
    "        TF = DTCM.T / DTCM.T.sum()\n",
    "\n",
    "    elif tf_method == 'max':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "\n",
    "    elif tf_method == 'log':\n",
    "        TF = np.log10(1 + DTCM.T)\n",
    "\n",
    "    elif tf_method == 'raw':\n",
    "        TF = DTCM.T\n",
    "\n",
    "    elif tf_method == 'double_norm':\n",
    "        TF = DTCM.T / DTCM.T.max()\n",
    "        TF = tf_norm_k + (1 - tf_norm_k) * TF[TF > 0] # EXPLAIN; may defeat purpose of norming\n",
    "\n",
    "    elif tf_method == 'binary':\n",
    "        TF = DTCM.T.astype('bool').astype('int')\n",
    "    TF = TF.T\n",
    "    N = DTCM.shape[0]\n",
    "    DF = DTCM[DTCM > 0].count()\n",
    "    \n",
    "    if idf_method == 'standard':\n",
    "        IDF = np.log10(N / DF)\n",
    "\n",
    "    elif idf_method == 'max':\n",
    "        IDF = np.log10(DF.max() / DF) \n",
    "\n",
    "    elif idf_method == 'smooth':\n",
    "        IDF = np.log10((1 + N) / (1 + DF)) + 1 # Correct?\n",
    "    \n",
    "    TFIDF = TF * IDF\n",
    "    \n",
    "    return TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0271324d-725e-402f-b6d7-f3ad7ee7dd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "LANG = OHCO[:4]\n",
    "SONG = OHCO[:3]\n",
    "ARTIST = OHCO[:2]\n",
    "GENRE = OHCO[:1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cbb090-26af-40c0-8beb-dff8f5e2d3a4",
   "metadata": {},
   "source": [
    "### We Will Make A TFIDF Table Bagged By Language\n",
    "\n",
    "This is our lowest level bagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3cf8983f-5ee9-43c9-95b9-be74e722bad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_type = 'n'\n",
    "tf_method = 'sum' \n",
    "tf_norm_k = .5 \n",
    "idf_method = 'standard' \n",
    "TFIDF = TFIDF_FUNCTION(TOKEN, LANG, count_type, tf_method, idf_method )\n",
    "TFIDF.head(5)\n",
    "\n",
    "#Add Results to VOCAB TAble\n",
    "VOCAB['tfidf_mean'] = TFIDF[TFIDF > 0].mean().fillna(0) \n",
    "VOCAB['tfidf_sum'] = TFIDF.sum()\n",
    "VOCAB['tfidf_median'] = TFIDF[TFIDF > 0].median().fillna(0) # EXPLAIN\n",
    "VOCAB['tfidf_max'] = TFIDF.max()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b342633-6393-42db-a679-47eb6ceee508",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB.to_csv('VOCAB.csv')\n",
    "LIB.to_csv('LIB.csv')\n",
    "TOKEN.to_csv('TOKEN.csv')\n",
    "TFIDF.to_csv('TFIDF.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
